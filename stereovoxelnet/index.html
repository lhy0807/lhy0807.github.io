<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="StereoVoxelNet: Real-Time Obstacle Detection Based on Occupancy Voxels From a Stereo Camera Using Deep Neural Networks.">
  <meta name="keywords" content="StereoVoxelNet, Obstacle Detection">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>StereoVoxelNet: Real-Time Obstacle Detection Based on Occupancy Voxels From a Stereo Camera Using Deep Neural
    Networks</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0N75MEWQ2J"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-0N75MEWQ2J');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/northeastern.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">StereoVoxelNet: Real-Time Obstacle Detection Based on Occupancy
              Voxels From a Stereo Camera Using Deep Neural Networks</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://lhy.xyz">Hongyu Li</a><sup>1,2</sup>,</span>
              <span class="author-block">
                Zhengang Li<sup>3*</sup>,</span>
              <span class="author-block">
                Neset Unver Akmandor<sup>1,3*</sup>,
              </span>
              <span class="author-block">
                <a href="https://jianghz.me/">Huaizu Jiang</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://web.northeastern.edu/yanzhiwang/">Yanzhi Wang</a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="https://coe.northeastern.edu/people/padir-taskin/">Taskin Padir</a><sup>1,3</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup><a href="https://robotics.northeastern.edu/">Institute for
                  Experiential Robotics, Northeastern Univerisity</a></span>
              <span class="author-block"><sup>2</sup>Khoury College of Computer Sciences, Northeastern University</span>
              <span class="author-block"><sup>3</sup>Department of Electrical and Computer Engineering, Northeastern
                University</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="./static/stereovoxelnet.pdf" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2209.08459" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=hvY_JYWlJOE" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/RIVeR-Lab/stereovoxelnet" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://app.globus.org/file-manager?origin_id=09b35740-377b-11ed-89ce-ede5bae4f491&origin_path=%2F" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/video/hie.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">StereoVoxelNet</span> generates voxels from a stereo pair
          to represent the detected location of the obstacles at the
          range of 32 meters in a coarse-to-fine manner.
        </h2>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Obstacle detection is a safety-critical problem in robot navigation, where stereo matching is a popular
              vision-based approach.
              While deep neural networks have shown impressive results in computer vision, most of the previous obstacle
              detection works only leverage traditional stereo matching techniques to meet the computational constraints
              for real-time feedback. This paper proposes a computationally efficient method that leverages a deep
              neural network to detect occupancy from stereo images. Instead of learning the point cloud correspondence
              from the stereo data, our approach extracts the compact obstacle distribution based on volumetric
              representations. In addition, we prune the computation of safety irrelevant spaces in a coarse-to-fine
              manner based on octrees generated by the decoder. As a result, we achieve real-time performance on the
              onboard computer (NVIDIA Jetson TX2). Our approach detects obstacles accurately in the range of 32 meters
              and achieves better IoU (Intersection over Union) and CD (Chamfer Distance) scores
              with only 2% of the computation cost of the state-of-the-art stereo model. Furthermore, we validate our
              method's robustness and real-world feasibility through autonomous navigation experiments with a real
              robot. Hence, our work contributes toward closing the gap between the stereo-based system in robot
              perception and state-of-the-art stereo models in computer vision. To counter the scarcity of high-quality
              real-world indoor stereo datasets, we collect a 1.36 hours stereo dataset with a Jackal robot which is
              used to fine-tune our model.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/hvY_JYWlJOE?rel=0&amp;showinfo=0" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->
  </section>

  <!-- <section class="section">
    <div class="container is-max-desktop">

      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Qualitative Result</h2>
      </div>

      <div class="columns is-centered has-text-centered">
        <div class="column">
          <video id="teaser" autoplay muted loop playsinline height="100%">
            <source src="./static/video/30-gt.mov" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            <span>Groundtruth
          </h2>
        </div>
        <div class="column">
          <video id="teaser" autoplay muted loop playsinline height="100%">
            <source src="./static/video/30-voxel.mov" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            <span class="is-bold">Ours
          </h2>
        </div>
      </div>
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <video id="teaser" autoplay muted loop playsinline height="100%">
            <source src="./static/video/30-sgbm.mov" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            <span>SGM
          </h2>
        </div>
        <div class="column">
          <video id="teaser" autoplay muted loop playsinline height="100%">
            <source src="./static/video/30-lac.mov" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            <span>Lac-GwcNet
          </h2>
        </div>
      </div>
    </div>
  </section> -->

  <section class="section">
    <div class="container is-max-desktop">

      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Qualitative Result</h2>
      </div>

    </div>
  </section>

  <section class="hero is-light is-medium">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
              <source src="./static/video/2-final.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item">
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
              <source src="./static/video/9-final.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item">
            <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
              <source src="./static/video/11-final.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item">
            <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
              <source src="./static/video/24-final.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item">
            <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
              <source src="./static/video/30-final.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item">
            <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
              <source src="./static/video/36-final.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item">
            <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
              <source src="./static/video/41-final.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>



  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
      @inproceedings{li2023stereovoxelnet,
        title = {StereoVoxelNet: Real-Time Obstacle Detection Based on Occupancy Voxels from a Stereo Camera Using Deep Neural Networks},
        author = {Li, Hongyu and Li, Zhengang and Akmandor, Neset Unver and Jiang, Huaizu and Wang, Yanzhi and Padir, Taskin},
        booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
        year={2023}
      }
      </code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="#">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="#" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is modified from the <a href="https://github.com/nerfies/nerfies.github.io">source
                code</a> of <a href="https://nerfies.github.io/">Nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>